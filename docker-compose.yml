version: "3"

services:
  # elasticsearch:
  #   image: docker.elastic.co/elasticsearch/elasticsearch:7.15.0
  #   environment:
  #     - discovery.type=single-node
  #   ports:
  #     - "9200:9200"
  #     - "9300:9300"
  redis:
    image: bitnami/redis:6.2
    container_name: redis
    restart: always
    ports:
      - "6379:6379"
    command: >
      redis-server --save 20 1 --loglevel warning
                  --protected-mode no
                  --requirepass redis
    volumes:
      - redis-data:/bitnami/redis/data
    networks:
      - services


  db-customer:
    image: postgres
    ports:
      - "5432:5432"
    restart: always
    volumes:
      - db-customer-data:/var/lib/postgresql/data
      # - ./init.sql:/docker-entrypoint-initdb.d/init.sql # This will run the init.sql script on the first run
    networks:
      - services
    environment:
      - POSTGRES_DB=customer
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    # expose:
    #   - 5432 # Expose this port internally for docker containers on the same network
  db-product:
    image: postgres
    ports:
      - "5433:5433"
    expose:
      - "5433"
    restart: always
    volumes:
      - db-product-data:/var/lib/postgresql/data # Persist the data
      # - ./init.sql:/docker-entrypoint-initdb.d/init.sql # This will run the init.sql script on the first run
    networks:
      - services
    environment:
      - POSTGRES_DB=product
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres

  # config-server:
  #   build:
  #     context: ./config-server
  #   container_name: config-server
  #   ports:
  #     - "8888:8888"
  #   depends_on:
  #     - cache
  #     - kafka
  #     - cassandra
  #   networks:
  #     - services
  #   healthcheck:
  #     test: 'curl --fail --silent localhost:8080/actuator/health | jq --exit-status -n ''inputs | if has("status") then .status=="UP" else false end'' > /dev/null || exit 1'
  #     interval: 20s
  #     timeout: 5s
  #     retries: 3
  #     start_period: 15s

  discovery:
    build:
      context: ./discovery
    container_name: discovery
    ports:
      - "8761:8761"
    networks:
      - services


  gateway:
    build:
      context: ./gateway
    container_name: gateway
    ports:
      - "8222:8222"
    depends_on:
      - discovery
      - redis
    networks:
      - services

  customer:
    build:
      context: ./customer-service
    container_name: customer
    ports:
      - "8090:8090"
    environment:
     - LOGSTASH_HOST=log
     - LOGSTASH_PORT=5044
    depends_on:
      - gateway
      - db-customer
      - kafka
      - logstash
      - prometheus
    networks:
      - services

  session-service:
   build:
     context: ./session-service
   container_name: session-service
   ports:
     - "8030:8030"
   environment:
     - SPRING_KAFKA_BOOTSTRAP_SERVERS=kafka:9092
     - SPRING_KAFKA_CONSUMER_BOOTSTRAP_SERVERS=kafka:9092
     - SPRING_KAFKA_PRODUCER_BOOTSTRAP_SERVERS=kafka:9092
     - SPRING_CASSANDRA_HOST=cassandra
     - SPRING_CASSANDRA_CONTACT_POINTS=cassandra
     - LOGSTASH_HOST=log
     - LOGSTASH_PORT=5044
   depends_on:
     - gateway
     - cassandra
     - logstash
     - prometheus
   networks:
     - services



  product-service:
   build:
     context: ./product-service
   container_name: product-service
   ports:
     - "8070:8070"
   environment:
     - SPRING_DATASOURCE_URL=jdbc:postgresql://db-product:5432/product
     - SPRING_KAFKA_BOOTSTRAP_SERVERS=kafka:9092
     - SPRING_KAFKA_CONSUMER_BOOTSTRAP_SERVERS=kafka:9092
     - SPRING_KAFKA_PRODUCER_BOOTSTRAP_SERVERS=kafka:9092
     - SPRING_DATA_REDIS_HOST=redis
     - SPRING_DATA_REDIS_PORT=6379
     - SPRING_REDIS_PASSWORD=redis
     - SPRING_CASSANDRA_HOST=cassandra
     - SPRING_CASSANDRA_CONTACT_POINTS=cassandra
     - LOGSTASH_HOST=log
     - LOGSTASH_PORT=5044
   depends_on:
     - gateway
     - db-product
     - redis
     - cassandra
     - logstash
     - prometheus
   networks:
     - services

  notification-service:
    build:
      context: ./notification-service
    container_name: notification-service
    ports:
      - "8020:8020"
    environment:
      - SPRING_KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - SPRING_KAFKA_CONSUMER_BOOTSTRAP_SERVERS=kafka:9092
      - SPRING_KAFKA_PRODUCER_BOOTSTRAP_SERVERS=kafka:9092
      - LOGSTASH_HOST=log
      - LOGSTASH_PORT=5044
    depends_on:
      - gateway
      - logstash
      - prometheus
    networks:
      - services



  zookeeper:
    image: docker.io/bitnami/zookeeper:3.9
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ALLOW_ANONYMOUS_LOGIN: "yes"
    networks:
      - services

  kafka:
    image: docker.io/bitnami/kafka:3.4
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: "1"
      KAFKA_LISTENERS: PLAINTEXT_INTERNAL://localhost:29092,PLAINTEXT://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT_INTERNAL://localhost:29092,PLAINTEXT://kafka:9092
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      ALLOW_PLAINTEXT_LISTENER: "yes"
    depends_on:
      - zookeeper
    networks:
      - services

  cassandra:
    image: cassandra:latest
    container_name: cassandra
    ports:
      - "9042:9042"
    environment:
      CASSANDRA_USER: "admin"
      CASSANDRA_PASSWORD: "admin"
    volumes:
      - cassandra-data:/var/lib/cassandra
      - ./scripts/cassandra_init.sh:/init.sh
    networks:
      - services

  elasticsearch:
   image: elasticsearch:7.16.1
   container_name: es
   environment:
     discovery.type: single-node
     ES_JAVA_OPTS: "-Xms512m -Xmx512m"

   ports:
     - "9200:9200"
     - "9300:9300"
   healthcheck:
     test:
       [
         "CMD-SHELL",
         "curl --silent --fail localhost:9200/_cluster/health || exit 1",
       ]
     interval: 10s
     timeout: 10s
     retries: 3
   networks:
     - services

  logstash:
   image: logstash:7.16.1
   container_name: log
   environment:
     discovery.seed_hosts: logstash
     LS_JAVA_OPTS: "-Xms512m -Xmx512m"
   volumes:
     - ./elasticsearch-logstash-kibana/logstash/pipeline/logstash-nginx.config:/usr/share/logstash/pipeline/logstash-nginx.config
     - ./elasticsearch-logstash-kibana/logstash/nginx.log:/home/nginx.log
   ports:
     - "5044:5044"
     - "9600:9600"
   depends_on:
     - elasticsearch
   networks:
     - services
   command: logstash -f /usr/share/logstash/pipeline/logstash-nginx.config

# create an index then go to discover to view the data 
  kibana:
   image: kibana:7.16.1
   container_name: kib
   ports:
     - "5601:5601"
   depends_on:
     - elasticsearch
   networks:
     - services


  prometheus:
   image: prom/prometheus
   container_name: prometheus
   command:
     - "--config.file=/etc/prometheus/prometheus.yml"
   ports:
     - 9090:9090
   restart: unless-stopped
   networks:
     - services
   volumes:
     - ./prometheus-grafana/prometheus:/etc/prometheus
     - prom_data:/prometheus

# import a dashboard with id 11378
  grafana:
   image: grafana/grafana
   container_name: grafana
   ports:
     - 3000:3000
   restart: unless-stopped
   environment:
     - GF_SECURITY_ADMIN_USER=admin
     - GF_SECURITY_ADMIN_PASSWORD=grafana
   networks:
     - services
   volumes:
     - ./prometheus-grafana/grafana:/etc/grafana/provisioning/datasources

volumes:
  cassandra-data:
  redis-data:
  db-product-data:
    driver: local
  db-customer-data:
    driver: local
  prom_data:

networks:
  services:
    driver: bridge
